================================================================================
                    DECEPTITECH - PROJECT DOCUMENTATION
                    Dark Pattern Detection Browser Extension
================================================================================

Document Version: 1.0
Last Updated: 2024
Project Location: working-extension/

================================================================================
1. PROJECT OVERVIEW
================================================================================

1.1 What This Project Does
---------------------------
DeceptiTech is a comprehensive browser extension that automatically detects 
and analyzes dark patterns on web pages. Dark patterns are deceptive user 
interface designs that manipulate users into making decisions they might not 
otherwise make, such as purchasing products, sharing personal information, or 
subscribing to services.

The extension combines multiple detection methods:
- Heuristic analysis using keyword matching and pattern recognition
- DOM element inspection for suspicious UI components
- Machine learning classification via a local NLP service
- Real-time monitoring of page changes

1.2 Purpose and Target Users
----------------------------
Purpose:
- Protect users from manipulative web design practices
- Increase awareness of dark patterns in digital interfaces
- Provide detailed analysis and reporting of detected patterns
- Enable users to make more informed decisions online

Target Users:
- Privacy-conscious internet users
- Researchers studying dark patterns and deceptive design
- Web developers and designers learning about ethical UI/UX
- Consumer protection advocates
- General users who want to understand manipulative web tactics

1.3 Key Features
----------------
- Real-time dark pattern detection on any webpage
- Detection of 7 major dark pattern categories:
  * Urgency (countdown timers, limited-time offers)
  * Scarcity (low stock indicators, exclusive availability)
  * Social Proof (user counters, popularity indicators)
  * Forced Action (mandatory actions, blocked progress)
  * Misdirection (confusing UI elements, misleading buttons)
  * Obstruction (hidden cancellation, difficult opt-out)
  * Sneaking (pre-checked boxes, hidden costs)
- Beautiful React-based user interface with animations
- PDF export functionality for generating reports
- Chrome/Chromium browser compatibility
- Optional NLP layer for enhanced pattern verification
- Continuous monitoring of dynamic page changes
- Pattern confidence scoring and filtering


================================================================================
2. TECHNOLOGY STACK
================================================================================

2.1 Frontend Technologies
--------------------------
Core Framework:
- React 18.2.0 - Component-based UI framework
- React DOM 18.2.0 - React rendering for web

UI Libraries:
- Framer Motion 10.16.4 - Animation library for smooth transitions
- React Icons 4.11.0 - Icon component library
- ClassNames 2.3.2 - Conditional CSS class management

Data Visualization:
- Chart.js 4.4.0 - Charting library
- React-Chartjs-2 5.2.0 - React wrapper for Chart.js

PDF Generation:
- jsPDF 2.5.1 - PDF document generation
- html2canvas 1.4.1 - HTML to canvas conversion for PDF export

Fonts:
- @fontsource/inter 5.2.8 - Inter font family
- @fontsource/poppins 5.2.7 - Poppins font family

Build Tools:
- Vite 4.5.0 - Fast build tool and development server
- @vitejs/plugin-react 4.1.1 - Vite plugin for React support

Browser APIs:
- Chrome Extensions API (Manifest V3)
  * chrome.runtime - Inter-component communication
  * chrome.tabs - Tab management and messaging
  * chrome.storage - Data persistence
  * chrome.scripting - Content script injection
  * chrome.notifications - User notifications

2.2 Backend Technologies
-------------------------
Web Framework:
- FastAPI 0.110+ - Modern Python web framework for API endpoints
- Uvicorn 0.23+ - ASGI server for running FastAPI

Machine Learning:
- Ollama (Local LLM Runtime) - Runs Qwen2.5:1.5B-Instruct model
- Qwen2.5:1.5B-Instruct - Lightweight instruction-tuned language model
  * ~700MB model size
  * CPU-friendly (no GPU required)
  * Fast inference (1-3 seconds per snippet)
  * Strict JSON output for classification

HTTP Client:
- httpx 0.24.0+ - Async HTTP client for API calls

Data Processing:
- Python 3.x - Core programming language
- CSV module - Dataset management
- hashlib - Text hashing for caching
- re (regex) - Pattern matching and text extraction

2.3 Data Storage
-----------------
- Chrome Storage API (chrome.storage.local/sync)
  * Extension settings
  * Detection history
  * Pattern cache
- CSV File System Storage
  * Dataset file: processed_not balanced_dataset.csv
  * Stores verified patterns with UIDs
  * Text, labels, categories, metadata

2.4 Development Tools
---------------------
- Node.js 16+ - JavaScript runtime
- npm - Package manager
- Python Virtual Environment (.venv) - Dependency isolation
- Git - Version control (implied)

2.5 Deployment Tools
--------------------
- Vite Build System - Production bundle generation
- Custom Build Scripts:
  * scripts/copy-extension.js - Extension file copying
  * build-and-run.bat - Automated build and setup
- Chrome Extension Distribution:
  * Unpacked extension loading
  * Developer mode installation


================================================================================
3. ARCHITECTURE AND COMMUNICATION
================================================================================

3.1 System Architecture Overview
---------------------------------
The DeceptiTech extension follows a multi-layered architecture:

┌─────────────────────────────────────────────────────────────┐
│                    Chrome Browser                            │
├─────────────────────────────────────────────────────────────┤
│                                                               │
│  ┌──────────────┐    ┌──────────────┐    ┌──────────────┐  │
│  │   Content    │    │  Background  │    │   React UI   │  │
│  │    Script    │◄──►│   Service    │◄──►│   (Side      │  │
│  │  (content.js)│    │  Worker      │    │   Panel/     │  │
│  │              │    │(background.js)│   │   Popup)     │  │
│  └──────┬───────┘    └──────┬───────┘    └──────────────┘  │
│         │                   │                                │
│         │                   │                                │
│         │                   ▼                                │
│         │         ┌──────────────────┐                       │
│         │         │  Chrome Storage  │                       │
│         │         │      API         │                       │
│         │         └──────────────────┘                       │
│         │                                                     │
│         └───────────────────┐                                 │
│                             ▼                                 │
│                  ┌─────────────────────┐                      │
│                  │   Web Page DOM      │                      │
│                  │  (MutationObserver) │                      │
│                  └─────────────────────┘                      │
└─────────────────────────────────────────────────────────────┘
                              │
                              │ HTTP POST
                              ▼
┌─────────────────────────────────────────────────────────────┐
│              NLP Service (Local Server)                      │
│              http://127.0.0.1:8001                           │
├─────────────────────────────────────────────────────────────┤
│                                                               │
│  ┌─────────────────────────────────────────────────────┐   │
│  │         FastAPI Application (server.py)              │   │
│  │                                                       │   │
│  │  Endpoints:                                          │   │
│  │  - POST /verify-patterns                            │   │
│  │  - POST /generate-description                       │   │
│  │  - POST /update-dataset                             │   │
│  └───────────────────┬─────────────────────────────────┘   │
│                      │                                       │
│                      ▼                                       │
│  ┌─────────────────────────────────────────────────────┐   │
│  │         Ollama Client (httpx)                        │   │
│  │         http://127.0.0.1:11434/api/generate         │   │
│  └───────────────────┬─────────────────────────────────┘   │
│                      │                                       │
│                      ▼                                       │
│  ┌─────────────────────────────────────────────────────┐   │
│  │    Qwen2.5:1.5B-Instruct Model (via Ollama)         │   │
│  └─────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────┘

3.2 Component Communication Flow
----------------------------------

A. Content Script → Background Script
   - Method: chrome.runtime.sendMessage()
   - Messages:
     * DARK_PATTERN_DETECTED - New patterns found
     * SCAN_REQUEST - Manual scan trigger
     * VERIFY_PATTERNS - Request pattern verification
     * GENERATE_DESCRIPTION - Request description generation
     * UPDATE_DATASET - Add patterns to dataset
     * NEW_PATTERNS_DETECTED - New patterns during monitoring

B. Background Script → Content Script
   - Method: chrome.tabs.sendMessage()
   - Messages:
     * PERFORM_SCAN - Trigger page scan
     * Response callbacks for verification/description requests

C. Background Script → NLP Service
   - Method: HTTP POST requests (fetch API)
   - Endpoints:
     * http://127.0.0.1:8001/verify-patterns
     * http://127.0.0.1:8001/generate-description
     * http://127.0.0.1:8001/update-dataset
   - Timeout: 2.5-15 seconds (varies by endpoint)
   - CORS: Enabled for all origins (extension runs on arbitrary pages)

D. React UI → Background Script
   - Method: chrome.runtime.sendMessage()
   - Messages:
     * SCAN_REQUEST - User-initiated scan
     * GET_SETTINGS - Retrieve extension settings
     * UPDATE_SETTINGS - Update extension settings

E. React UI → Content Script (via Background)
   - Indirect communication through background script
   - Background forwards messages to content script in active tab

3.3 API Routes and Endpoints
-----------------------------

NLP Service Endpoints (FastAPI):

1. POST /verify-patterns
   Request Body:
   {
     "patterns": [
       {
         "id": "unique-id",
         "text": "pattern text snippet",
         "category": "Urgency",
         "confidence": 0.85,
         ...
       }
     ]
   }
   
   Response:
   {
     "verified": [
       {
         "id": "unique-id",
         "text": "pattern text snippet",
         "is_dark_pattern": true,
         "category": "Urgency",
         "confidence": 0.92,
         "explanation": "This text creates artificial urgency..."
       }
     ]
   }
   
   Purpose: Verify detected patterns using ML model, filter false positives

2. POST /generate-description
   Request Body:
   {
     "category": "Urgency",
     "text": "pattern text snippet"
   }
   
   Response:
   {
     "description": "Urgency pattern detected: This text creates..."
   }
   
   Purpose: Generate human-readable explanations for detected patterns

3. POST /update-dataset
   Request Body:
   {
     "patterns": [
       {
         "text": "pattern text",
         "category": "Urgency",
         "label": 1
       }
     ]
   }
   
   Response:
   {
     "added": 5,
     "skipped": 2,
     "message": "Added 5 new entries, skipped 2 duplicates"
   }
   
   Purpose: Add verified patterns to training dataset CSV file

3.4 Data Flow Between Components
----------------------------------

Pattern Detection Flow:

1. Page Load/User Action
   ↓
2. Content Script (content.js)
   - Scans DOM for dark pattern indicators
   - Applies heuristic rules (keyword matching, DOM inspection)
   - Collects candidate patterns
   ↓
3. Optional: NLP Verification (if service available)
   - Content script sends patterns to background
   - Background forwards to NLP service
   - NLP service queries Ollama/Qwen model
   - Model returns classification with confidence
   - Results sent back to content script
   ↓
4. Pattern Aggregation
   - Content script combines heuristic + ML results
   - Deduplicates patterns
   - Assigns confidence scores
   ↓
5. Results Storage
   - Patterns sent to background script
   - Background stores in chrome.storage.local
   - Detection history updated
   ↓
6. UI Update
   - Background notifies React UI
   - React UI displays patterns in side panel/popup
   - User can filter, sort, and export results

3.5 Authentication and Security
--------------------------------
- No user authentication required (local extension)
- All processing happens locally (NLP service on localhost)
- No external API calls (except optional Ollama service)
- CORS enabled for localhost only
- Chrome storage API for data persistence (local to browser)
- No sensitive data transmitted externally

3.6 Third-Party Integrations
-----------------------------
- Ollama (Local LLM Runtime)
  * Runs Qwen2.5:1.5B-Instruct model
  * Accessed via HTTP API at http://127.0.0.1:11434
  * Must be installed and running separately
  * Model must be pulled: ollama pull qwen2.5:1.5b-instruct


================================================================================
4. WORKFLOW DESCRIPTIONS
================================================================================

4.1 Extension Installation Workflow
-------------------------------------
Trigger: User loads extension in Chrome

Steps:
1. User navigates to chrome://extensions/
2. Enables "Developer mode"
3. Clicks "Load unpacked"
4. Selects working-extension/dist folder
5. Extension installs and background service worker initializes
6. Background script sets default settings:
   - autoScan: true
   - showNotifications: true
   - scanInterval: 5000ms
   - confidenceThreshold: 0.6
7. Content script injects into all matching pages
8. Extension icon appears in Chrome toolbar

Output: Extension ready to use, content script active on web pages

4.2 Page Scan Workflow
-----------------------
Trigger: User clicks "Scan Current Page" button OR automatic scan on page load

Steps:
1. User Action:
   - User clicks extension icon (popup) OR
   - User clicks DeceptiTech widget on page OR
   - Page finishes loading (if auto-scan enabled)

2. Content Script Activation:
   - Content script receives PERFORM_SCAN message
   - Initializes detection state
   - Loads pattern descriptions from JSON file

3. DOM Analysis:
   - Scans all text nodes in document
   - Applies keyword matching for each category
   - Inspects form elements (checkboxes, radio buttons)
   - Checks for suspicious DOM patterns:
     * Pre-checked boxes
     * Hidden cancellation options
     * Confusing button labels
     * Countdown timers
     * Stock indicators

4. Pattern Detection:
   - For each candidate pattern:
     * Extracts text snippet (max 300 chars)
     * Matches against category keywords
     * Applies DOM rules
     * Calculates initial confidence score
     * Generates unique pattern ID

5. Optional NLP Verification:
   - If NLP service available:
     * Batches patterns (max 200 items)
     * Sends to background script
     * Background forwards to NLP service
     * Service queries Ollama/Qwen model
     * Model classifies each pattern
     * Returns verified patterns with confidence
   - If NLP service unavailable:
     * Uses heuristic results only
     * Falls back to keyword-based confidence

6. Pattern Aggregation:
   - Combines heuristic + ML results
   - Deduplicates patterns (same text within 5 seconds)
   - Filters by confidence threshold (default: 0.6)
   - Preserves high-confidence patterns (>= 0.7)
   - Special handling for Scarcity/Obstruction patterns

7. Description Generation:
   - For each verified pattern:
     * Requests description from NLP service (if available)
     * Falls back to category-specific template
     * Formats: "Category pattern detected: [snippet preview]"

8. Results Transmission:
   - Content script sends patterns to background
   - Background stores in chrome.storage.local
   - Background updates detection history
   - Background notifies React UI

9. UI Display:
   - React UI receives patterns
   - Displays in side panel or popup
   - Shows pattern cards with:
     * Category badge
     * Confidence score
     * Description
     * Text snippet
     * Expandable details

Output: List of detected dark patterns displayed in UI with confidence scores

4.3 Real-Time Monitoring Workflow
-----------------------------------
Trigger: Page changes detected via MutationObserver

Steps:
1. Content Script Initialization:
   - Sets up MutationObserver on document body
   - Monitors DOM changes (childList, subtree, characterData)

2. Change Detection:
   - Observer fires on DOM mutations
   - Buffers changes for 5 seconds (BATCH_INTERVAL_MS)
   - Collects new text nodes and elements

3. Pattern Detection:
   - Scans new/changed elements
   - Applies same detection rules as manual scan
   - Compares with previous scan results

4. New Pattern Identification:
   - Compares current patterns with previous patterns
   - Identifies newly detected patterns
   - Filters duplicates

5. Notification:
   - If new patterns found:
     * Sends NEW_PATTERNS_DETECTED message to background
     * Background creates Chrome notification
     * Updates extension badge with count
     * Optionally updates UI automatically

Output: User notified of new dark patterns as page changes

4.4 Pattern Verification Workflow
----------------------------------
Trigger: Patterns detected and NLP service available

Steps:
1. Pattern Collection:
   - Content script collects candidate patterns
   - Batches up to 200 patterns

2. Verification Request:
   - Content script sends VERIFY_PATTERNS message to background
   - Background receives request with pattern array

3. NLP Service Call:
   - Background constructs HTTP POST request
   - Endpoint: http://127.0.0.1:8001/verify-patterns
   - Body: { "patterns": [...] }
   - Timeout: 15 seconds

4. Model Processing:
   - FastAPI receives request
   - For each pattern:
     * Checks cache (LRU cache, 500 entries)
     * If not cached, builds prompt for Qwen model
     * Prompts model to classify pattern
     * Extracts JSON response from model output
     * Validates response structure
     * Caches result

5. Response Processing:
   - Service returns verified patterns
   - Only patterns with is_dark_pattern: true included
   - Confidence scores updated from model output

6. Results Return:
   - Background receives response
   - Forwards to content script
   - Content script merges with heuristic results

Output: Verified patterns with ML-enhanced confidence scores

4.5 Description Generation Workflow
------------------------------------
Trigger: Pattern needs human-readable description

Steps:
1. Description Request:
   - Content script or UI requests description
   - Sends GENERATE_DESCRIPTION message to background
   - Includes category and text snippet

2. NLP Service Call:
   - Background constructs HTTP POST request
   - Endpoint: http://127.0.0.1:8001/generate-description
   - Body: { "category": "...", "text": "..." }
   - Timeout: 15 seconds

3. Model Processing:
   - FastAPI receives request
   - Builds description prompt for Qwen model
   - Model generates explanation (1-2 sentences)
   - Service extracts and cleans response

4. Response Return:
   - Description returned to background
   - Background forwards to requester
   - UI displays description in pattern card

Output: Human-readable explanation of why pattern is deceptive

4.6 PDF Export Workflow
------------------------
Trigger: User clicks "Export PDF" button

Steps:
1. User Action:
   - User clicks export button in React UI
   - UI collects all filtered patterns

2. Report Generation:
   - Uses html2canvas to capture UI elements
   - Converts to canvas/image
   - Creates jsPDF document
   - Adds header with scan date/time
   - Adds summary statistics

3. Pattern Details:
   - For each pattern:
     * Category name
     * Confidence score
     * Description
     * Text snippet
     * Detection timestamp

4. PDF Creation:
   - Adds charts/graphs (if available)
   - Formats layout professionally
   - Sets page breaks appropriately

5. Download:
   - Triggers browser download
   - Filename: deceptitech-report-[timestamp].pdf

Output: PDF file downloaded to user's computer

4.7 Dataset Update Workflow
----------------------------
Trigger: User verifies patterns and adds to training dataset

Steps:
1. Pattern Verification:
   - User reviews detected patterns
   - Marks patterns as verified/correct

2. Update Request:
   - UI sends UPDATE_DATASET message to background
   - Includes array of verified patterns

3. Dataset Processing:
   - Background forwards to NLP service
   - Service receives patterns
   - For each pattern:
     * Generates deterministic UID (SHA256 hash)
     * Checks if UID exists in CSV file
     * If new, prepares entry:
       - text: original text
       - label: 1 (dark pattern) or 0 (not dark pattern)
       - Pattern Category: category name
       - text_length: word count
       - clean_text: normalized text
       - UID: unique identifier

4. CSV Append:
   - Opens dataset CSV file
   - Appends new entries (skips duplicates)
   - Preserves existing data

5. Response:
   - Returns count of added/skipped entries
   - UI displays confirmation message

Output: Training dataset updated with new verified patterns


================================================================================
5. FRONTEND DETAILS
================================================================================

5.1 UI/UX Structure
--------------------

A. Extension Popup (popup.html)
   - Location: Chrome toolbar icon click
   - Size: Compact, fixed dimensions
   - Components:
     * Header with DeceptiTech logo/title
     * "Scan Current Page" button
     * Quick stats (pattern count)
     * Link to open side panel

B. Side Panel (React UI)
   - Location: Injected into web page or Chrome side panel
   - Mount Point: #app-mount div (injected by content script)
   - Layout: Full-height panel with tabs
   - Sections:
     * Scan Tab: Manual scan interface
     * Results Tab: Pattern list and details
     * Summary Tab: Statistics and charts

C. Injected Widget (Optional)
   - Location: Floating button on web page
   - Trigger: User interaction
   - Purpose: Quick access to scanner

5.2 Functional Components
--------------------------

Main Components (React):

1. App.jsx (Main Application)
   - State Management:
     * patterns: Array of detected patterns
     * filters: Category and sort filters
     * isScanning: Scan in progress flag
     * theme: Light/dark mode
     * currentPage: Navigation state
   - Functions:
     * handleScanSubmit(): Initiates page scan
     * handleExportPDF(): Generates PDF report
     * handleFilterChange(): Updates filter state
     * pushToast(): Shows notification messages

2. PatternList.jsx (Pattern Display)
   - Props: items (array of patterns)
   - Features:
     * Renders pattern cards
     * Expandable details
     * Category badges with icons
     * Confidence bars
     * Color-coded by category
   - PatternCard Sub-component:
     * Displays individual pattern
     * Shows category, confidence, description
     * Expandable for full text snippet

3. Summary.jsx (Statistics)
   - Props: patterns (array)
   - Features:
     * Pattern count by category
     * Pie chart visualization
     * Average confidence score
     * Total patterns detected
   - Charts: Uses Chart.js with react-chartjs-2

5.3 API Consumption
--------------------

A. Chrome Extension APIs:
   - chrome.runtime.sendMessage()
     * Sends messages to background script
     * Handles responses asynchronously
   - chrome.tabs.query()
     * Gets active tab information
     * Checks if page is scannable
   - chrome.tabs.sendMessage()
     * Sends messages to content script
     * Receives scan results

B. NLP Service API (via Background):
   - Indirect consumption through background script
   - Background handles HTTP requests
   - UI receives processed results

5.4 Interface Updates
----------------------

A. Real-Time Updates:
   - React state updates trigger re-renders
   - Framer Motion animations for smooth transitions
   - Toast notifications for user feedback

B. Pattern Display:
   - Filters applied via useMemo hook
   - Sorting by confidence (ascending/descending)
   - Category filtering
   - Animated card appearances

C. Loading States:
   - Scanning indicator during detection
   - Skeleton loaders for async data
   - Progress feedback

5.5 Styling and Theming
------------------------
- CSS Modules: styles.css for component styles
- Theme Support: Light/dark mode toggle
- Responsive Design: Adapts to panel/popup sizes
- Color Scheme:
  * Urgency: #ef4444 (red)
  * Scarcity: #4a90e2 (blue)
  * Social Proof: #6366f1 (indigo)
  * Forced Action: #f97316 (orange)
  * Misdirection: #f59e0b (amber)
  * Obstruction: #a3a3a3 (gray)
  * Sneaking: #a855f7 (purple)
- Typography: Inter and Poppins fonts
- Animations: Framer Motion for transitions


================================================================================
6. BACKEND DETAILS
================================================================================

6.1 API Structure and Endpoints
--------------------------------

FastAPI Application (server.py):

Base URL: http://127.0.0.1:8001

Endpoints:

1. POST /verify-patterns
   - Purpose: Verify detected patterns using ML model
   - Request Schema:
     {
       "patterns": [
         {
           "id": string,
           "text": string,
           "category": string,
           "confidence": float,
           ...
         }
       ]
     }
   - Response Schema:
     {
       "verified": [
         {
           "id": string,
           "text": string,
           "is_dark_pattern": boolean,
           "category": string,
           "confidence": float,
           "explanation": string
         }
       ]
     }
   - Processing:
     * Checks cache for each pattern
     * If not cached, queries Ollama/Qwen model
     * Extracts JSON from model response
     * Validates required fields
     * Returns only verified dark patterns

2. POST /generate-description
   - Purpose: Generate human-readable pattern descriptions
   - Request Schema:
     {
       "category": string,
       "text": string
     }
   - Response Schema:
     {
       "description": string
     }
   - Processing:
     * Builds description prompt
     * Queries Ollama/Qwen model
     * Extracts and cleans response
     * Returns formatted description

3. POST /update-dataset
   - Purpose: Add verified patterns to training dataset
   - Request Schema:
     {
       "patterns": [
         {
           "text": string,
           "category": string,
           "label": integer (0 or 1)
         }
       ]
     }
   - Response Schema:
     {
       "added": integer,
       "skipped": integer,
       "message": string
     }
   - Processing:
     * Generates UID for each pattern
     * Checks for duplicates in CSV
     * Appends new entries to CSV file
     * Returns count of added/skipped entries

6.2 Business Logic Layers
---------------------------

A. Pattern Verification Layer:
   - Input: Candidate patterns from content script
   - Process:
     1. Text normalization
     2. Cache lookup (LRU cache, 500 entries)
     3. Prompt construction for Qwen model
     4. Model inference via Ollama API
     5. JSON extraction and validation
     6. Result caching
   - Output: Verified patterns with ML confidence

B. Description Generation Layer:
   - Input: Category and text snippet
   - Process:
     1. Template selection based on category
     2. Prompt construction
     3. Model inference
     4. Response cleaning and formatting
   - Output: Human-readable description

C. Dataset Management Layer:
   - Input: Verified patterns
   - Process:
     1. UID generation (deterministic hash)
     2. Duplicate detection
     3. Text cleaning and normalization
     4. CSV formatting
     5. File append operation
   - Output: Updated CSV dataset

6.3 Model Inference
--------------------

Model: Qwen2.5:1.5B-Instruct
- Runtime: Ollama (local)
- Endpoint: http://127.0.0.1:11434/api/generate
- Model Size: ~700MB
- Inference Time: 1-3 seconds per snippet
- Hardware: CPU-friendly (no GPU required)

Inference Process:
1. Prompt Construction:
   - Template-based prompts
   - Includes category definitions
   - Requests JSON-only output
   - Includes example format

2. API Call:
   - HTTP POST to Ollama API
   - Async request with httpx
   - Timeout: 30 seconds
   - Stream: false (non-streaming)

3. Response Processing:
   - Extract JSON from model output
   - Use regex to find JSON objects
   - Parse and validate structure
   - Handle malformed responses gracefully

4. Caching:
   - LRU cache (500 entries)
   - Hash-based key (SHA256 of text)
   - Reduces redundant inference calls

6.4 Processing and Validation
------------------------------

A. Input Validation:
   - Pydantic models for request validation
   - Type checking (VerifyRequest, DescRequest, DatasetUpdateRequest)
   - Required field validation

B. Text Processing:
   - Normalization: lowercase, strip whitespace
   - Cleaning: remove special characters for CSV
   - Truncation: max 300 characters for snippets
   - Deduplication: hash-based comparison

C. Output Validation:
   - JSON structure validation
   - Required field checking (is_dark_pattern, category)
   - Confidence score range (0-1)
   - Category name normalization

6.5 Storage
-----------

A. In-Memory Cache:
   - LRU cache for model results
   - 500 entry limit
   - Hash-based keys
   - Reduces API calls to Ollama

B. File System Storage:
   - CSV file: processed_not balanced_dataset.csv
   - Location: nlp_service/ directory
   - Format:
     * text: Original pattern text
     * label: 1 (dark pattern) or 0 (not dark pattern)
     * Pattern Category: Category name
     * text_length: Word count
     * clean_text: Normalized text
     * UID: Unique identifier (16-char hash)
   - Append-only (no deletions)
   - Duplicate prevention via UID checking

6.6 Error Handling
------------------
- Try-catch blocks around all API calls
- Graceful fallbacks if Ollama unavailable
- Empty response handling
- Timeout management (30 seconds for inference)
- CSV file error handling
- Logging for debugging


================================================================================
7. DEPLOYMENT FLOW
================================================================================

7.1 Build Process
------------------

Step 1: Install Dependencies
   Command: npm install
   Location: working-extension/
   Purpose: Install React, Vite, and all frontend dependencies
   Output: node_modules/ directory created

Step 2: Build React Application
   Command: npm run build
   Location: working-extension/
   Process:
     * Vite compiles React components
     * Bundles JavaScript and CSS
     * Optimizes assets
     * Outputs to dist/ directory
   Output: dist/assets/ with bundled files

Step 3: Copy Extension Files
   Command: node scripts/copy-extension.js
   Location: working-extension/
   Process:
     * Copies manifest.json to dist/
     * Copies background.js to dist/
     * Copies content.js to dist/
     * Copies popup.html to dist/
     * Copies popup.js to dist/
     * Copies data/ directory to dist/
   Output: Complete extension in dist/ directory

Alternative: Automated Build
   Command: build-and-run.bat (Windows)
   Process: Runs npm install, npm run build, and copy script sequentially

7.2 Extension Installation
---------------------------

Step 1: Prepare Extension
   - Ensure dist/ directory contains all files
   - Verify manifest.json is valid
   - Check that all referenced files exist

Step 2: Load in Chrome
   - Open Chrome browser
   - Navigate to chrome://extensions/
   - Enable "Developer mode" (toggle in top-right)
   - Click "Load unpacked" button
   - Select working-extension/dist folder
   - Extension appears in extensions list

Step 3: Verify Installation
   - Check extension icon in toolbar
   - Verify no errors in extension details
   - Test popup opens correctly

7.3 NLP Service Setup
----------------------

Step 1: Install Ollama
   - Download from ollama.ai
   - Install on local machine
   - Verify installation: ollama --version

Step 2: Pull Model
   Command: ollama pull qwen2.5:1.5b-instruct
   Purpose: Download Qwen2.5 model to local machine
   Output: Model stored in Ollama's model directory

Step 3: Create Python Virtual Environment
   Command: python -m venv .venv
   Location: working-extension/nlp_service/
   Purpose: Isolate Python dependencies

Step 4: Activate Virtual Environment
   Windows: .venv\Scripts\activate
   Linux/Mac: source .venv/bin/activate
   Purpose: Use isolated Python environment

Step 5: Install Python Dependencies
   Command: pip install -r requirements.txt
   Location: working-extension/nlp_service/
   Dependencies:
     * fastapi
     * uvicorn
     * httpx
     * (others from requirements.txt)

Step 6: Start NLP Service
   Command: python start_server.py
   Location: working-extension/nlp_service/
   Process:
     * Starts Uvicorn ASGI server
     * Binds to 127.0.0.1:8001
     * Loads FastAPI application
   Output: Server running, ready to accept requests

Alternative: Batch Script
   Command: start_server_windows.bat
   Purpose: Automated server startup on Windows

7.4 Server Configuration
-------------------------

NLP Service:
   - Host: 127.0.0.1 (localhost only)
   - Port: 8001
   - Protocol: HTTP
   - CORS: Enabled for all origins (required for extension)
   - Reload: Disabled (production mode)

Ollama Service:
   - Host: 127.0.0.1
   - Port: 11434 (default)
   - Protocol: HTTP
   - Endpoint: /api/generate

7.5 Environment Configuration
------------------------------

Extension Configuration (content.js):
   - NLP_ENABLED: true/false
   - NLP_ENDPOINT: "http://127.0.0.1:8001/predict" (legacy, not used)
   - NLP_VERIFY_ENDPOINT: "http://127.0.0.1:8001/verify-patterns"
   - NLP_DESCRIPTION_ENDPOINT: "http://127.0.0.1:8001/generate-description"
   - NLP_REQUEST_TIMEOUT_MS: 2500 (default)
   - CONFIDENCE_THRESHOLD: 0.6

Background Script Configuration:
   - NLP service URL: http://127.0.0.1:8001
   - Timeout: 5000-15000ms (varies by endpoint)

7.6 Reverse Proxy (Not Applicable)
------------------------------------
- No reverse proxy required
- Direct localhost communication
- No external deployment
- All services run locally

7.7 Deployment Verification
------------------------------

Checklist:
   ✓ Extension loads without errors
   ✓ Content script injects on web pages
   ✓ Background service worker active
   ✓ NLP service responds to HTTP requests
   ✓ Ollama service running and accessible
   ✓ Model loaded in Ollama
   ✓ Extension can communicate with NLP service
   ✓ Pattern detection works on test page
   ✓ UI displays results correctly

Testing:
   1. Open test-page.html in browser
   2. Click extension icon
   3. Click "Scan Current Page"
   4. Verify patterns detected
   5. Check NLP verification (if service running)
   6. Test PDF export
   7. Verify notifications work


================================================================================
8. FUTURE ENHANCEMENTS
================================================================================

8.1 Detection Improvements
---------------------------

A. Enhanced ML Models:
   - Upgrade to larger, more accurate models
   - Fine-tune models on domain-specific data
   - Ensemble multiple models for better accuracy
   - Support for multilingual pattern detection

B. Advanced Heuristics:
   - Visual pattern recognition (screenshot analysis)
   - Behavioral pattern detection (user interaction tracking)
   - Temporal analysis (pattern changes over time)
   - Cross-page pattern correlation

C. Real-Time Learning:
   - Online learning from user feedback
   - Automatic model retraining
   - A/B testing for detection rules
   - Continuous improvement pipeline

8.2 User Experience Enhancements
----------------------------------

A. Interface Improvements:
   - Dark mode support (partial, needs completion)
   - Customizable themes
   - Accessibility improvements (screen reader support)
   - Mobile browser support (Firefox, Safari)

B. Reporting Features:
   - Export to multiple formats (CSV, JSON, HTML)
   - Scheduled reports
   - Pattern trend analysis
   - Historical comparison

C. User Customization:
   - Custom pattern categories
   - User-defined detection rules
   - Sensitivity settings per category
   - Whitelist/blacklist websites

8.3 Performance Optimizations
------------------------------

A. Caching Improvements:
   - Persistent cache across browser sessions
   - Shared cache between tabs
   - Prefetching for common patterns
   - Incremental scanning (only new content)

B. Processing Optimization:
   - Web Workers for heavy computation
   - Parallel pattern detection
   - Lazy loading of UI components
   - Reduced memory footprint

C. Network Optimization:
   - Batch API requests more efficiently
   - Compress requests/responses
   - Connection pooling
   - Request prioritization

8.4 Scalability Options
------------------------

A. Cloud Deployment:
   - Deploy NLP service to cloud (AWS, GCP, Azure)
   - Use managed ML services (AWS SageMaker, etc.)
   - Horizontal scaling for high traffic
   - CDN for static assets

B. Distributed Architecture:
   - Microservices for different functions
   - Message queue for async processing
   - Database for pattern storage
   - API gateway for routing

C. Multi-User Support:
   - User accounts and authentication
   - Shared pattern database
   - Community pattern reporting
   - Pattern verification by experts

8.5 Integration Enhancements
------------------------------

A. Browser Support:
   - Firefox extension (WebExtensions API)
   - Safari extension
   - Edge extension
   - Cross-browser compatibility

B. Third-Party Integrations:
   - Integration with privacy tools (uBlock Origin, etc.)
   - Reporting to consumer protection agencies
   - Sharing with research databases
   - API for external applications

C. Developer Tools:
   - Browser DevTools integration
   - Pattern debugging tools
   - Performance profiling
   - Pattern simulation/testing

8.6 Data and Analytics
-----------------------

A. Pattern Database:
   - Centralized pattern repository
   - Pattern frequency statistics
   - Industry-specific analysis
   - Geographic pattern distribution

B. Research Features:
   - Academic research mode
   - Anonymized data export
   - Pattern evolution tracking
   - Comparative analysis tools

C. Community Features:
   - User-submitted patterns
   - Pattern verification by community
   - Discussion forums
   - Educational resources

8.7 Security and Privacy
-------------------------

A. Privacy Enhancements:
   - Local-only processing (no data sent externally)
   - Encrypted storage
   - User data anonymization
   - Privacy-preserving analytics

B. Security Improvements:
   - Content Security Policy (CSP) compliance
   - Secure communication channels
   - Input sanitization
   - Regular security audits

8.8 Documentation and Support
------------------------------

A. Documentation:
   - User guide with screenshots
   - Developer documentation
   - API documentation
   - Video tutorials

B. Support:
   - FAQ section
   - Troubleshooting guide
   - Community support forum
   - Issue reporting system


================================================================================
9. APPENDIX: KEY FILES AND STRUCTURE
================================================================================

9.1 Project Directory Structure
---------------------------------

working-extension/
├── src/                          # React source code
│   ├── ui/
│   │   ├── App.jsx               # Main React component
│   │   ├── PatternList.jsx       # Pattern display component
│   │   ├── Summary.jsx           # Statistics component
│   │   └── styles.css            # Component styles
│   ├── main.jsx                  # React entry point
│   └── index.css                 # Base styles
├── dist/                         # Built extension (output)
│   ├── assets/                   # Bundled JS/CSS
│   ├── background.js             # Service worker
│   ├── content.js                # Content script
│   ├── manifest.json             # Extension manifest
│   ├── popup.html                # Extension popup
│   ├── popup.js                  # Popup script
│   └── data/
│       └── pattern-descriptions.json
├── nlp_service/                  # Backend NLP service
│   ├── server.py                 # FastAPI application
│   ├── start_server.py           # Server startup script
│   ├── requirements.txt          # Python dependencies
│   ├── processed_not balanced_dataset.csv  # Training dataset
│   └── .venv/                    # Python virtual environment
├── scripts/
│   └── copy-extension.js         # Build script
├── manifest.json                 # Extension manifest (source)
├── background.js                 # Background script (source)
├── content.js                    # Content script (source)
├── popup.html                    # Popup HTML (source)
├── popup.js                      # Popup script (source)
├── package.json                  # Node.js dependencies
├── vite.config.js               # Vite configuration
├── test-page.html               # Test page with dark patterns
└── README.md                    # Project readme

9.2 Configuration Files
-------------------------

manifest.json:
   - Extension metadata
   - Permissions and host permissions
   - Content script configuration
   - Background service worker
   - Web accessible resources

package.json:
   - Node.js dependencies
   - Build scripts
   - Project metadata

vite.config.js:
   - Build configuration
   - Output directory settings
   - React plugin configuration

requirements.txt:
   - Python dependencies
   - Version specifications

9.3 Data Files
---------------

pattern-descriptions.json:
   - Detailed descriptions for each category
   - Examples of each pattern type
   - Educational content

processed_not balanced_dataset.csv:
   - Training dataset
   - Verified patterns
   - Text, labels, categories, UIDs


================================================================================
END OF DOCUMENTATION
================================================================================

For questions or issues, refer to:
- README.md - Quick start guide
- SETUP_AND_RUN.md - Detailed setup instructions
- QUICK_START.md - Fast setup guide
- FINALIZED_SUMMARY.md - Feature summary

